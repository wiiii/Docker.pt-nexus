# .github/workflows/douban_imdb_cf.yml

name: æ›´æ–° cf è±†ç“£-IMDb æ˜ å°„æ•°æ®åº“

on:
  workflow_dispatch:

  schedule:
    - cron: '0 0 * * 0'

jobs:
  import-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Latest Wrangler
        run: npm install -g wrangler@latest

      - name: Create Wrangler Config File
        run: |
          DB_NAME="pt-nexus"
          
          echo "name = \"d1-importer-project\"" > wrangler.toml
          echo "compatibility_date = \"$(date +'%Y-%m-%d')\"" >> wrangler.toml
          echo "" >> wrangler.toml
          echo "[[d1_databases]]" >> wrangler.toml
          echo "binding = \"$DB_NAME\"" >> wrangler.toml
          echo "database_name = \"$DB_NAME\"" >> wrangler.toml
          echo "database_id = \"${{ secrets.CLOUDFLARE_D1_DATABASE_ID }}\"" >> wrangler.toml
          
          echo "Wrangler config file created:"
          cat wrangler.toml

      - name: Download JSON data
        run: |
          JSON_URL="https://raw.githubusercontent.com/ourbits/PtGen/refs/heads/main/internal_map/douban_imdb_map.json"
          curl -o data.json "$JSON_URL"

      - name: Create and run import script
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          cat <<'EOF' > import.mjs
          import fs from 'fs';
          import { execSync } from 'child_process';

          const DATABASE_NAME = 'pt-nexus';
          const INPUT_FILE = './data.json';
          const BATCH_SIZE = 1000;

          function escapeSqlValue(value) {
            if (value === null || typeof value === 'undefined') {
              return 'NULL';
            }
            return `'${String(value).replace(/'/g, "''")}'`;
          }

          async function main() {
            console.log(`[æ­¥éª¤ 1/2] è¯»å–æœ¬åœ°å·²ä¸‹è½½çš„æ•°æ®...`);
            const content = fs.readFileSync(INPUT_FILE, 'utf-8');
            const allData = JSON.parse(content);
            console.log(`è¯»å–æˆåŠŸ! å…± ${allData.length} æ¡è®°å½•ã€‚`);

            console.log(`[æ­¥éª¤ 2/2] å¼€å§‹åˆ†æ‰¹å¯¼å…¥æ•°æ®åˆ°äº‘ç«¯...`);
            for (let i = 0; i < allData.length; i += BATCH_SIZE) {
              const batch = allData.slice(i, i + BATCH_SIZE);
              const currentBatchNum = i / BATCH_SIZE + 1;
              const totalBatches = Math.ceil(allData.length / BATCH_SIZE);
              
              const valuesString = batch.map(item => 
                `(${escapeSqlValue(item.dbid)}, ${escapeSqlValue(item.imdbid)}, ${escapeSqlValue(item.name)}, ${escapeSqlValue(item.year)})`
              ).join(',');

              if (!valuesString) continue;

              const fullSql = `INSERT OR IGNORE INTO "douban-imdb" (doubanid, imdbid, name, year) VALUES ${valuesString};`;
              const escapedSql = fullSql.replace(/'/g, "'\\''");

              const command = `wrangler d1 execute ${DATABASE_NAME} --remote --command '${escapedSql}'`;
              
              try {
                console.log(`æ­£åœ¨æ¨é€ç¬¬ ${currentBatchNum} / ${totalBatches} æ‰¹æ•°æ®...`);
                execSync(command, { stdio: 'inherit' });
              } catch (e) {
                console.error(`ç¬¬ ${currentBatchNum} æ‰¹æ•°æ®æ¨é€å¤±è´¥:`, e.message);
                process.exit(1);
              }
            }

            console.log('ğŸ‰ å…¨éƒ¨æ•°æ®å¯¼å…¥/æ›´æ–°æˆåŠŸ!');
          }

          main();
          EOF
          
          node import.mjs
